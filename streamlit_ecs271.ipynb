{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h7dlJRcetU-",
        "outputId": "5cc96a86-08f9-48fe-d5aa-8df5b5c8023d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install scikit-learn\n",
        "! pip install keras\n",
        "! pip install keras_multi_head\n",
        "! pip install librosa\n",
        "! pip install streamlit -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjFWeTd3fslO",
        "outputId": "c6059111-c128-4aac-e516-879189196b2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3NxHIRllB_D",
        "outputId": "3bc1cab0-eab0-41ff-9989-a1c15fce361a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "App.py file is the code file behind what's displayed on the web streamlit app"
      ],
      "metadata": {
        "id": "h-MMA5i1hfa4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3D08qm8Fzx0",
        "outputId": "0879c903-1fdb-4f40-845b-a11bfb194a40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import librosa\n",
        "import librosa.display\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from keras_multi_head import MultiHead\n",
        "\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/ecs_271/SER_model_3.h5', custom_objects={'MultiHead': MultiHead})\n",
        "\n",
        "\n",
        "def shifting(data,rate=1000):\n",
        "    augmented_data=int(np.random.uniform(low=-5,high=5)*rate)\n",
        "    augmented_data=np.roll(data,augmented_data)\n",
        "    return augmented_data\n",
        "\n",
        "def pitch(data,sr,pitch_factor=0.7,random = False):\n",
        "    if random:\n",
        "        pitch_factor=np.random.random() * pitch_factor\n",
        "    return librosa.effects.pitch_shift(data,sr=sr, n_steps=pitch_factor)\n",
        "\n",
        "def stretching(data,rate=0.8):\n",
        "    return librosa.effects.time_stretch(data,rate =rate)\n",
        "\n",
        "def extract_features(data,sampling_rate):\n",
        "\n",
        "    result = np.array([])\n",
        "\n",
        "    #Zero Crossing Rate\n",
        "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T,axis=0)\n",
        "    result = np.hstack((result,zcr))\n",
        "\n",
        "    #mfcc\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=data,sr = sampling_rate).T,axis=0)\n",
        "    result = np.hstack((result,mfcc))\n",
        "\n",
        "    #root mean square val\n",
        "    rms = np.mean(librosa.feature.rms(y=data).T,axis=0)\n",
        "    result = np.hstack((result,rms))\n",
        "\n",
        "    #MelSpectogram\n",
        "    melspectogram = np.mean(librosa.feature.melspectrogram(y=data,sr = sampling_rate).T, axis=0)\n",
        "    result = np.hstack((result,melspectogram))\n",
        "\n",
        "    return result\n",
        "\n",
        "def get_features(path):\n",
        "    # duration and offset are used to take care of the no audio in start and the ending of each audio files.\n",
        "    data, sampling_rate = librosa.load(path,duration = 2.5, offset =0.6)\n",
        "\n",
        "    audio1 = extract_features(data,sampling_rate)\n",
        "    result = np.array(audio1)\n",
        "\n",
        "    # data with stretching and pitching\n",
        "    stretched_audio = stretching(data)\n",
        "    pitched_audio = pitch(stretched_audio,sampling_rate)\n",
        "    audio3 = extract_features(pitched_audio,sampling_rate)\n",
        "    result = np.vstack((result,audio3))\n",
        "\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def main():\n",
        "    st.title(\"VoiceVibe: Unleashing Emotion with Speech Emotion Recognition\")\n",
        "    st.write(f\"\"\"\n",
        "    Virtual Assistants and chatbots have significantly narrowed the gap between humans and AI. Through the\n",
        "    integration of Human-in-the Loop techniques and Human-Computer Interaction (HCI) policies, these assistants are\n",
        "    now able to answer human needs. ChatGPT stands as a prominent example. offering responses to all questions,\n",
        "    while there are other virtual assistants that operate for a specific cause (e.g., Counseling Services). Our focus is on\n",
        "    improving and making online counseling services more accessible to everyone. Recognizing that not everyone can\n",
        "    articulate their emotions in text. To better understand the emotional state of the person by analyzing voice tone,\n",
        "    pitch, and intonation, we propose the use of Speech Emotion Recognition (SER) integration with the assistant. In\n",
        "    this application, the person can verbally communicate with the assistant and ask for help. Using SER, the assistant\n",
        "    can understand the person's state and offer appropriate feedback. This will further help build trust between humans\n",
        "    and AI, which is a crucial principle in HCI.\n",
        "    \"\"\")\n",
        "\n",
        "\n",
        "    st.write(\"In order to recognize the emotion, Upload the speech audio here: \")\n",
        "\n",
        "    encoding_dictionary ={0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', 4: 'neutral', 5: 'sad', 6: 'surprise'}\n",
        "    uploaded_file = st.file_uploader(\"\", type=[\"wav\"], key='unique_id_1')\n",
        "    if uploaded_file is not None:\n",
        "      st.audio(uploaded_file, format='audio/wav')\n",
        "      feature = get_features(uploaded_file)\n",
        "      pred_data = model.predict(feature)\n",
        "      encoder = OneHotEncoder()\n",
        "      pred_labels_encoded = np.argmax(pred_data, axis=1)\n",
        "      st.write(f\"Predicted Label: {encoding_dictionary[pred_labels_encoded[0]]}\")\n",
        "\n",
        "    st.write(\"##### You can take sample audio files from here: https://drive.google.com/drive/folders/1QrVXYcsf5moqNT0dGig-PN9OitbFCeWQ?usp=sharing\")\n",
        "\n",
        "    st.write(\"#### Group Members:\", markdown=True)\n",
        "\n",
        "\n",
        "\n",
        "    members_info = [\n",
        "    {\"Name\": \"Taher Travedi\", \"Photo\": \"https://i.postimg.cc/Qxt91zLD/Taher.jpg\", \"Email\": \"ttravadi@ucdavis.edu\", \"LinkedIn\": \"https://www.linkedin.com/in/taher-travadi/\"},\n",
        "    {\"Name\": \"Nikita B. Emberi\", \"Photo\": \"https://i.postimg.cc/QNKBFBvb/Nikita-ML.jpg\", \"Email\": \"nemberi@ucdavis.edu\", \"LinkedIn\": \"https://www.linkedin.com/in/nikitaemberi/\"},\n",
        "    {\"Name\": \"Savali Deshmukh\", \"Photo\": \"https://i.postimg.cc/jSYwysy7/savali-ML.jpg\", \"Email\": \"sdeshmukh@ucdavis.edu\", \"LinkedIn\": \"https://www.linkedin.com/in/savali-d-2092611a6/\"},\n",
        "    ]\n",
        "\n",
        "    # Create three columns\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "\n",
        "    # Insert information into each column\n",
        "    for member_info, col in zip(members_info, [col1, col2, col3]):\n",
        "        with col:\n",
        "            st.subheader(member_info[\"Name\"])\n",
        "            st.image(member_info['Photo'], caption=member_info['Name'], use_column_width=True)\n",
        "            st.write(f\"Email: {member_info['Email']}\")\n",
        "            st.write(f\"LinkedIn: {member_info['LinkedIn']}\")\n",
        "\n",
        "    footer = \"\"\"\n",
        "    <style>\n",
        "        .footer {\n",
        "            position: fixed;\n",
        "            bottom: 0;\n",
        "            left: 0;\n",
        "            width: 100%;\n",
        "            background-color: #2c3e50; /* Dark gray background color */\n",
        "            color: #ecf0f1; /* Light text color */\n",
        "            text-align: center;\n",
        "            padding: 10px;\n",
        "        }\n",
        "    </style>\n",
        "    <div class=\"footer\">\n",
        "        <p>ECS 271 Project. CopyRight: All Rights Reserved.</p>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    # Display the footer using the st.markdown function\n",
        "    st.markdown(footer, unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "  main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuJ2EQjZXVya",
        "outputId": "f8c30420-b2ea-430c-c3c9-a9223d4862f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.237.146.203\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enter above ip address before accessing streamlit app through local tunnel"
      ],
      "metadata": {
        "id": "stZwY1A9hTjQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFWkN8E1XqYo",
        "outputId": "799b63e3-d556-4934-97a0-a082bc4d9bf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.237.146.203:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.498s\n",
            "your url is: https://heavy-candies-type.loca.lt\n",
            "2023-12-15 12:44:50.093224: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-15 12:44:50.093301: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-15 12:44:50.095066: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-15 12:44:50.107394: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-15 12:44:51.719603: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-12-15 12:44:57.613 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2023-12-15 12:44:57.615 Invalid arguments were passed to \"st.write\" function. Support for passing such unknown keywords arguments will be dropped in future. Invalid arguments were: {'markdown': True}\n",
            "2023-12-15 12:45:23.930 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "2023-12-15 12:45:31.040 Invalid arguments were passed to \"st.write\" function. Support for passing such unknown keywords arguments will be dropped in future. Invalid arguments were: {'markdown': True}\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "! streamlit run app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nRrhHjpPsV_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}